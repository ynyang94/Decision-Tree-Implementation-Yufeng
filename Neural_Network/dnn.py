# -*- coding: utf-8 -*-
"""DNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V0IMtPe8b2mrSLXGpTjgpb12JvNnAyom
"""

# The code is initially implemented using Google Colab.
# Link: https://colab.research.google.com/drive/1V0IMtPe8b2mrSLXGpTjgpb12JvNnAyom?usp=sharing

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd

class CustomDataset(Dataset):
    def __init__(self, csv_file, transform=None):
        self.data_frame = pd.read_csv(csv_file)
        self.transform = transform

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        sample = self.data_frame.iloc[idx, :-1].values.astype(float)  # Input features
        label = float(self.data_frame.iloc[idx, -1])  # Output label

        # Apply transformation: set label to 1 if it's smaller than 0, otherwise -1
        label = 1 if label > 0 else -1

        if self.transform:
            sample = self.transform(sample)
        return sample, label
# Define the neural network

class ThreeLayerNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, choice = 0):
        super(ThreeLayerNN, self).__init__()
        if choice == 0:
          self.layer1 = nn.Linear(input_size, hidden_size)
          nn.init.kaiming_uniform_(self.layer1.weight, mode='fan_in', nonlinearity='relu')

          self.layer2 = nn.Linear(hidden_size, hidden_size)
          nn.init.kaiming_uniform_(self.layer2.weight, mode='fan_in', nonlinearity='relu')
        elif choice == 1:
            self.layer1 = nn.Linear(input_size, hidden_size)
            nn.init.xavier_uniform_(self.layer1.weight, gain=nn.init.calculate_gain('tanh'))

            self.layer2 = nn.Linear(hidden_size, hidden_size)
            nn.init.xavier_uniform_(self.layer2.weight, gain=nn.init.calculate_gain('tanh'))


        self.layer3 = nn.Linear(hidden_size, output_size)

    def forward(self, x, depth):
        x = torch.relu(self.layer1(x))
        for i in range(depth-2):
          x = torch.relu(self.layer2(x))
        #x = torch.relu(self.layer2(x))
        x = self.layer3(x)
        return x

# Data loading and transformation
# 
csv_file_path = 'train.csv'
train_dataset = CustomDataset(csv_file=csv_file_path)
test_data = pd.read_csv('test.csv')
hidden_size_list = [5,10,25,50,100]

for hidden_size in hidden_size_list:
  train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True)

  # Assuming input size is the number of features in each data point
  input_size = len(train_dataset[0][0])
  output_size = 1  # Binary classification

  # Initialize the model, loss function, and optimizer
  model = ThreeLayerNN(input_size, hidden_size=hidden_size, output_size=output_size,choice = 0)
  criterion = nn.MSELoss()  # Binary Cross Entropy Loss for binary classification
  optimizer = optim.Adam(model.parameters(), lr=0.001)

  # Ensure model and input data have the same data type
  model = model.to(torch.float32)

  # Training loop
  num_epochs = 50
  train_err_list = []
  for epoch in range(num_epochs):
      train_err = 0
      for inputs, labels in train_dataloader:
          optimizer.zero_grad()
          outputs = model(inputs.to(torch.float32),depth = 9)

          # Apply transformation: set labels to 1 if they are smaller than 0, otherwise -1
          transformed_labels = torch.where(labels > 0, torch.tensor(1.0), torch.tensor(-1.0))
          true_labels = transformed_labels.detach()
          predict_labels = outputs.detach()
          predict_labels = torch.sign(predict_labels)
          loss = criterion(outputs, transformed_labels.view(-1, 1))
          loss.backward()
          optimizer.step()
          train_err = torch.sum(torch.abs(predict_labels.reshape(-1,1) - true_labels.reshape(-1,1)))/(2*predict_labels.shape[0])
          train_err_list.append(train_err)
      #print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')
  print('train error',torch.mean(torch.tensor(train_err_list)))

  #test

  test_err = 0
  predicted_label = []
  for i in range(len(test_data)):
      sample = test_data.iloc[i, :-1].values.astype(float)
      test_data_tensor = torch.tensor(sample, dtype=torch.float32).view(1, -1)
      output = model(test_data_tensor,depth = 9)
      predicted_class = torch.sign(output).item()
      predicted_label.append(predicted_class)
      #print(f'Instance {i+1}, Predicted Class: {predicted_class}')
  true_label = torch.tensor(test_data.iloc[:, -1])
  true_label = torch.sign(true_label)
  predicted_label = torch.tensor(predicted_label)
  predicted_label[predicted_label < 0 ] = 0
  predicted_label = torch.tensor(predicted_label)
  test_err = torch.sum(torch.abs(true_label - predicted_label))/( true_label.shape[0])
  print('test error', test_err)







